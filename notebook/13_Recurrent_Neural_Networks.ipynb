{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMGKeQ70b2tFZV6MHrBGmr7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimgeonhee317/nlpdemystifed-notes/blob/main/notebook/13_Recurrent_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 13_Recurrent Neural Networks"
      ],
      "metadata": {
        "id": "z9u4MJ2Pjliq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Library"
      ],
      "metadata": {
        "id": "idcV9Ofejsq0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_LFKcmAZlM9"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import requests\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from nltk.corpus import treebank, brown, conll2000\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part-of-Speech Tagger with Bidirectional LSTM"
      ],
      "metadata": {
        "id": "moqKQkM4kTWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PoS tagging with LSTM is multiclass classification task for sequence.\n",
        "\n",
        "# nltk offers free sets for labelled corpora.\n",
        "# look at https://www.nltk.org/nltk_data\n",
        "nltk.download('treebank')\n",
        "nltk.download('brown')\n",
        "nltk.download('conll2000')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVb3M8AIkUFD",
        "outputId": "e333328e-14aa-411e-aa83-85785e69991e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download tagset\n",
        "nltk.download('universal_tagset')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rf1e3Hykk10t",
        "outputId": "575978bf-50e3-40c8-addd-803d03d1ce67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download all PoS-tagged sentences and place them in one List.\n",
        "tagged_sentences = treebank.tagged_sents(tagset='universal')+\\\n",
        "                   brown.tagged_sents(tagset='universal')+\\\n",
        "                   conll2000.tagged_sents(tagset='universal')\n",
        "print(tagged_sentences[0])\n",
        "print(f\"Dataset size: {len(tagged_sentences)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_SILV6OlagZ",
        "outputId": "552b3a18-a383-470d-af69-47d3995a055c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Pierre', 'NOUN'), ('Vinken', 'NOUN'), (',', '.'), ('61', 'NUM'), ('years', 'NOUN'), ('old', 'ADJ'), (',', '.'), ('will', 'VERB'), ('join', 'VERB'), ('the', 'DET'), ('board', 'NOUN'), ('as', 'ADP'), ('a', 'DET'), ('nonexecutive', 'ADJ'), ('director', 'NOUN'), ('Nov.', 'NOUN'), ('29', 'NUM'), ('.', '.')]\n",
            "Dataset size: 72202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences, sentence_tags = [], []\n",
        "\n",
        "for s in tagged_sentences:\n",
        "  sentence, tags = zip(*s) # multiple numbers of tuple according to sentences\n",
        "  sentences.append(list(sentence))\n",
        "  sentence_tags.append(list(tags))"
      ],
      "metadata": {
        "id": "fsG84AxsmBrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentences[0])\n",
        "print(sentence_tags[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuDNua06oEzi",
        "outputId": "b90ea104-9888-4a15-ac3e-834afdc8ca73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.']\n",
            "['NOUN', 'NOUN', '.', 'NUM', 'NOUN', 'ADJ', '.', 'VERB', 'VERB', 'DET', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', 'NOUN', 'NUM', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(sentences), len(sentence_tags)) # number of sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIgrWPASoJ8p",
        "outputId": "1a29ba2d-f0fd-4b49-c13d-35e6a45ee05c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "72202 72202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split dataset according to the proportion below\n",
        "train_ratio = 0.75\n",
        "validation_ratio = 0.15\n",
        "test_ratio=0.10\n",
        "\n",
        "# train:test = 0.75:0.25\n",
        "x_train, x_test, y_train, y_test = train_test_split(sentences, sentence_tags,\n",
        "                                                     test_size= 1-train_ratio,\n",
        "                                                     random_state = 317)\n",
        "# train:val:test = 0.75:0.15:0.10\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test,\n",
        "                                                test_size = test_ratio/(test_ratio + validation_ratio),\n",
        "                                                random_state = 317)"
      ],
      "metadata": {
        "id": "m64dEOEto4RY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(x_train), len(y_train))\n",
        "print(len(x_val), len(y_val))\n",
        "print(len(x_test), len(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oahgHkABp6-k",
        "outputId": "b5b2a14f-6275-43ba-cd48-a6adc1e0bd4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "54151 54151\n",
            "10830 10830\n",
            "7221 7221\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate wordvectors for our sentenses\n",
        "# default tokenizer, out-ov-vocabulary token as <OOV>\n",
        "sentence_tokenizer = keras.preprocessing.text.Tokenizer(oov_token='<OOV')\n",
        "sentence_tokenizer.fit_on_texts(x_train)\n",
        "print(f\"Vocabulary size: {len(sentence_tokenizer.word_index)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7XFgJzTqB2u",
        "outputId": "bcecb5d1-2072-4ee8-b796-62f9a5d1481b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 52183\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we need another tokenizer for the tags are also sequences.\n",
        "tag_tokenizer = keras.preprocessing.text.Tokenizer()\n",
        "tag_tokenizer.fit_on_texts(y_train)"
      ],
      "metadata": {
        "id": "BtzyVYOurvYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of PoS tags: {len(tag_tokenizer.word_index)}\\n\")\n",
        "tag_tokenizer.get_config()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arfXHis_sioK",
        "outputId": "487e2607-c91c-4916-c6ee-1022027f61cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of PoS tags: 12\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'num_words': None,\n",
              " 'filters': '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
              " 'lower': True,\n",
              " 'split': ' ',\n",
              " 'char_level': False,\n",
              " 'oov_token': None,\n",
              " 'document_count': 54151,\n",
              " 'word_counts': '{\"adv\": 51392, \"verb\": 175631, \"adp\": 137365, \"det\": 127600, \".\": 143593, \"adj\": 81110, \"noun\": 288313, \"conj\": 35420, \"num\": 21374, \"prt\": 31340, \"pron\": 44737, \"x\": 6109}',\n",
              " 'word_docs': '{\"conj\": 24581, \"det\": 44815, \"verb\": 50880, \"num\": 11905, \"adj\": 36440, \"noun\": 51202, \"adp\": 43937, \"adv\": 29599, \".\": 53331, \"prt\": 21888, \"pron\": 26974, \"x\": 2668}',\n",
              " 'index_docs': '{\"9\": 24581, \"5\": 44815, \"2\": 50880, \"11\": 11905, \"6\": 36440, \"1\": 51202, \"4\": 43937, \"7\": 29599, \"3\": 53331, \"10\": 21888, \"8\": 26974, \"12\": 2668}',\n",
              " 'index_word': '{\"1\": \"noun\", \"2\": \"verb\", \"3\": \".\", \"4\": \"adp\", \"5\": \"det\", \"6\": \"adj\", \"7\": \"adv\", \"8\": \"pron\", \"9\": \"conj\", \"10\": \"prt\", \"11\": \"num\", \"12\": \"x\"}',\n",
              " 'word_index': '{\"noun\": 1, \"verb\": 2, \".\": 3, \"adp\": 4, \"det\": 5, \"adj\": 6, \"adv\": 7, \"pron\": 8, \"conj\": 9, \"prt\": 10, \"num\": 11, \"x\": 12}'}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tag_tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwklrTqusjkL",
        "outputId": "0a8e59c7-1cc1-4f19-feeb-1aed5e92ed63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'noun': 1,\n",
              " 'verb': 2,\n",
              " '.': 3,\n",
              " 'adp': 4,\n",
              " 'det': 5,\n",
              " 'adj': 6,\n",
              " 'adv': 7,\n",
              " 'pron': 8,\n",
              " 'conj': 9,\n",
              " 'prt': 10,\n",
              " 'num': 11,\n",
              " 'x': 12}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert text to number sequences by fitted tokenizer\n",
        "x_train_seqs = sentence_tokenizer.texts_to_sequences(x_train)"
      ],
      "metadata": {
        "id": "4vYvnVhTtmOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train_seqs[0])\n",
        "print(x_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41PgV2eRt0BP",
        "outputId": "a42608eb-31ad-482c-d7a3-c17214164080"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[133, 1921, 19, 8, 13, 1606, 461, 15, 4344, 318, 12, 8, 1922, 28157, 1858, 25, 12287, 28158, 926, 926, 20609, 7, 6603, 6, 20610, 1568, 9, 3198, 39, 13, 145, 6, 1742, 23, 834, 295, 3038, 311, 28159, 32, 28160, 1284, 3, 11, 207, 20609, 1742, 429, 2072, 12288, 15, 4]\n",
            "['Still', 'existing', 'on', 'a', '``', 'Northern', 'Union', \"''\", 'telegraph', 'form', 'is', 'a', 'typical', 'peremptory', 'message', 'from', 'Peru', 'grocer', 'J.', 'J.', 'Hapgood', 'to', 'Burton', 'and', \"Graves'\", 'store', 'in', 'Manchester', '--', '``', 'Get', 'and', 'send', 'by', 'stage', 'four', 'pounds', 'best', 'Porterhouse', 'or', 'serloin', 'stake', ',', 'for', 'Mrs.', 'Hapgood', 'send', 'six', 'sweet', 'oranges', \"''\", '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_seqs = tag_tokenizer.texts_to_sequences(y_train)"
      ],
      "metadata": {
        "id": "OIwxOqfdt4D4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tag_tokenizer.sequences_to_texts([y_train_seqs[0]]))\n",
        "print(y_train_seqs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRyi-i-suIjq",
        "outputId": "a0ad622f-edc7-4e80-ea8f-8db4fba6d5bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['adv verb adp det . adj noun . noun noun verb det adj adj noun adp noun noun noun noun noun adp noun conj noun noun adp noun . . verb conj verb adp noun num noun adj noun conj noun noun . adp noun noun verb num adj noun . .']\n",
            "[7, 2, 4, 5, 3, 6, 1, 3, 1, 1, 2, 5, 6, 6, 1, 4, 1, 1, 1, 1, 1, 4, 1, 9, 1, 1, 4, 1, 3, 3, 2, 9, 2, 4, 1, 11, 1, 6, 1, 9, 1, 1, 3, 4, 1, 1, 2, 11, 6, 1, 3, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Do the same things to valid dataset\n",
        "x_val_seqs = sentence_tokenizer.texts_to_sequences(x_val)\n",
        "y_val_seqs = tag_tokenizer.texts_to_sequences(y_val)"
      ],
      "metadata": {
        "id": "7Vz817BkuSbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Even if RNN can handle variable lengthes of sequences, it is musch better for performance to unify the lengthes of each sequences\n",
        "print(len(max(x_train_seqs, key=len))) # return the length of the longest sequence\n",
        "MAX_LENGTH = len(max(x_train_seqs, key=len))\n",
        "print(f\"Length of longest input sequence: {MAX_LENGTH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5DE6_sOu4nV",
        "outputId": "aab55973-4d1c-4d50-9110-cac7804bc505"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "271\n",
            "Length of longest input sequence: 271\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can pad every sentences with method \"pad_sequences\" from keras\n",
        "x_train_padded = keras.preprocessing.sequence.pad_sequences(x_train_seqs, padding='post',\n",
        "                                                            maxlen=MAX_LENGTH)\n"
      ],
      "metadata": {
        "id": "WvjMFVPcviLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train_padded[0])\n",
        "print(len(x_train_padded[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIC3PRHuy1JK",
        "outputId": "4394167d-dea2-4e10-fd54-db753a14a97d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  133  1921    19     8    13  1606   461    15  4344   318    12     8\n",
            "  1922 28157  1858    25 12287 28158   926   926 20609     7  6603     6\n",
            " 20610  1568     9  3198    39    13   145     6  1742    23   834   295\n",
            "  3038   311 28159    32 28160  1284     3    11   207 20609  1742   429\n",
            "  2072 12288    15     4     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0]\n",
            "271\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# do the same things to training label\n",
        "y_train_padded = keras.preprocessing.sequence.pad_sequences(y_train_seqs, padding='post',\n",
        "                                                           maxlen=MAX_LENGTH)"
      ],
      "metadata": {
        "id": "PvY-cmPZy2zN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_val_padded = keras.preprocessing.sequence.pad_sequences(x_val_seqs, padding='post', maxlen=MAX_LENGTH)\n",
        "y_val_padded = keras.preprocessing.sequence.pad_sequences(y_val_seqs, padding='post', maxlen=MAX_LENGTH)"
      ],
      "metadata": {
        "id": "DTRgOeoXzHnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# As PoS tagging is a multiclass classification task done at each timestep,\n",
        "# we need to convert every tag for every sentence into one-hot encoding.\n",
        "y_train_categoricals = keras.utils.to_categorical(y_train_padded)\n",
        "print(y_train_categoricals[0]) # sequence is now composed of one-hot encodings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlg3RsmtzUoN",
        "outputId": "cc08f9b4-84b0-4a8f-cab6-f7864f5f2c68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# one-hot encoding for a single tag in a sequence\n",
        "print(y_train_categoricals[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENGlUOJjzt3J",
        "outputId": "34bcecbb-5c71-49dc-f485-b57bd3d0be23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can determind PoS tag from oh-encoding by \"look-up\" in index_word dictionary from tag_tokenizer\n",
        "idx = np.argmax(y_train_categoricals[0][0]) # argmax return the index of elememt having maximum value in OHencoding array\n",
        "print(f\"Index: {idx}\")\n",
        "print(f\"Tag: {tag_tokenizer.index_word[idx]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsctW0Fm0gLH",
        "outputId": "2ba2f708-f72f-43b4-9d8c-f74c3ea9f135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index: 7\n",
            "Tag: adv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# one hot encoding to val_labels\n",
        "y_val_categoricals = keras.utils.to_categorical(y_val_padded)"
      ],
      "metadata": {
        "id": "Gu4HHrym1E4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[notes]\n",
        "At this point, we're ready to build our model. We'll train word embeddings concurrently with our model (though you can use pretrained word vectors as well)."
      ],
      "metadata": {
        "id": "CQ_OyvCSzyKx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[notes]\n",
        "1. Ignore padding values :\n",
        "The embedding layers has *mask_zero* parameter. we added padding in order to make our batches the same size, but we don't want to makd PoS predictions on padding. Setting *mask_zero* to *True* makes the layers following the embedding layer ignore padding values.\n",
        "\n",
        "2. Return sequences not only one output :\n",
        "we're using *bidriectional LSTM*. The Bidrectional layer is a wrapper to which we pass an LSTM layer. The first parameter to the LSTM layer is the number of units in the cell. The second parameter, return_sequences, control whether the RNN returns an output for each timestep or only the last output. Since we're doing PoS-tagging, we want an aoutput for each timestep and so *return_sequences* is set to *True*."
      ],
      "metadata": {
        "id": "xepXLukU2YB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For the embedding layer. \"+1\" to account for the padding token.\n",
        "num_tokens = len(sentence_tokenizer.word_index) + 1 # +1 for padding token\n",
        "embedding_dim = 128\n",
        "\n",
        "# For the output layer, The number of classes corresponds to the number of possible tags\n",
        "num_classes = len(tag_tokenizer.word_index) + 1 # also +1 for padding token"
      ],
      "metadata": {
        "id": "x63KC0tG4Oaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we set random_set_seed and kerner_initializer parameter to get same result.\n",
        "tf.random.set_seed(317)\n",
        "\n",
        "model = keras.Sequential()\n",
        "\n",
        "# input layer(embedding layer : each tokens -> embedding_dim )\n",
        "model.add(layers.Embedding(input_dim = num_tokens,\n",
        "                           output_dim = embedding_dim,\n",
        "                           input_length = MAX_LENGTH,\n",
        "                           mask_zero=True))\n",
        "\n",
        "# hidden layer (bidrectional)\n",
        "model.add(layers.Bidirectional(layers.LSTM(128, return_sequences=True,\n",
        "                                           kernel_initializer=tf.keras.initializers.random_normal(seed=317))))\n",
        "\n",
        "# output layer for each timestep with softmax activation fucntion\n",
        "model.add(layers.Dense(num_classes, activation='softmax',\n",
        "                       kernel_initializer=tf.keras.initializers.random_normal(seed=317)))\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n"
      ],
      "metadata": {
        "id": "CX8V0jM057Hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kzrHF588OJi",
        "outputId": "bebe1f46-331c-4d47-cbb6-2ecd0f05ff67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 271, 128)          6679552   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 271, 256)         263168    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, 271, 13)           3341      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,946,061\n",
            "Trainable params: 6,946,061\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[notes] \\\n",
        "1. The embedding layer output has three dimensions\n",
        "- Batch size : None => we haven't specified it yet\n",
        "- Sequence length : 217\n",
        "- Embedding dimension : 128\n",
        "\n",
        "2. Bidirectional LSTM outputs a vector twice the size of what we specified because its bidirectional. Remember two LSTM output will be concatenated before going to output layer.\n",
        "\n",
        "3. Output layer also has three dimensions\n",
        "- Batch size\n",
        "- Sequence length\n",
        "- Output dimension : 13 as number of tag classes\n"
      ],
      "metadata": {
        "id": "U0WjEnpT7w1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we put early-stopping for trainig to be stopped when validation loss stops improving.\n",
        "es_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "history = model.fit(x_train_padded, y_train_categoricals, epochs=20,\n",
        "                    batch_size=256, validation_data=(x_val_padded, y_val_categoricals),\n",
        "                    callbacks=[es_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMSCaB708ZO1",
        "outputId": "8477a915-a062-4039-c8e4-eca7efeed24b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "212/212 [==============================] - 65s 239ms/step - loss: 0.9598 - accuracy: 0.7057 - val_loss: 0.1617 - val_accuracy: 0.9512\n",
            "Epoch 2/20\n",
            "212/212 [==============================] - 25s 117ms/step - loss: 0.1138 - accuracy: 0.9642 - val_loss: 0.1082 - val_accuracy: 0.9642\n",
            "Epoch 3/20\n",
            "212/212 [==============================] - 17s 81ms/step - loss: 0.0753 - accuracy: 0.9753 - val_loss: 0.0968 - val_accuracy: 0.9678\n",
            "Epoch 4/20\n",
            "212/212 [==============================] - 20s 94ms/step - loss: 0.0595 - accuracy: 0.9803 - val_loss: 0.0944 - val_accuracy: 0.9692\n",
            "Epoch 5/20\n",
            "212/212 [==============================] - 14s 66ms/step - loss: 0.0480 - accuracy: 0.9842 - val_loss: 0.0924 - val_accuracy: 0.9703\n",
            "Epoch 6/20\n",
            "212/212 [==============================] - 12s 57ms/step - loss: 0.0392 - accuracy: 0.9875 - val_loss: 0.0954 - val_accuracy: 0.9698\n",
            "Epoch 7/20\n",
            "212/212 [==============================] - 12s 55ms/step - loss: 0.0322 - accuracy: 0.9898 - val_loss: 0.0995 - val_accuracy: 0.9701\n",
            "Epoch 8/20\n",
            "212/212 [==============================] - 12s 55ms/step - loss: 0.0265 - accuracy: 0.9918 - val_loss: 0.1026 - val_accuracy: 0.9700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After our model is trained, go to test data set\n",
        "# preprocessing(tokenize, pad) it and oh encoding\n",
        "\n",
        "x_test_seqs = sentence_tokenizer.texts_to_sequences(x_test)\n",
        "x_test_padded = keras.preprocessing.sequence.pad_sequences(x_test_seqs, padding='post', maxlen=MAX_LENGTH)\n",
        "\n",
        "y_test_seqs = tag_tokenizer.texts_to_sequences(y_test)\n",
        "y_test_padded = keras.preprocessing.sequence.pad_sequences(y_test_seqs, padding='post', maxlen=MAX_LENGTH)\n",
        "y_test_categoricals = keras.utils.to_categorical(y_test_padded)"
      ],
      "metadata": {
        "id": "QqxYjmQn9ve9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test_padded, y_test_categoricals)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2n4n9Jly-ruD",
        "outputId": "2607734f-36d7-4a4a-cc63-98522d620bc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "226/226 [==============================] - 2s 10ms/step - loss: 0.1052 - accuracy: 0.9688\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1051989421248436, 0.9687950611114502]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now we can use our models to tag sentences.\n",
        "\n",
        "samples = [\n",
        "    \"Brown refused to testify.\",\n",
        "    \"Brown sofas are on sale\",\n",
        "]"
      ],
      "metadata": {
        "id": "_Ac9odm9-wJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# develop simple function for doing this task.\n",
        "\n",
        "def tag_sentences(sentences):\n",
        "  sentences_seqs = sentence_tokenizer.texts_to_sequences(sentences)\n",
        "  sentences_padded = keras.preprocessing.sequence.pad_sequences(sentences_seqs,\n",
        "                                                               maxlen=MAX_LENGTH,\n",
        "                                                               padding='post')\n",
        "  # tag_preds is each list of probabilty distribution (softmax)\n",
        "  tag_preds = model.predict(sentences_padded)\n",
        "\n",
        "  sentence_tags = []\n",
        "\n",
        "  # each iteration is one sequence\n",
        "  for i, preds in enumerate(tag_preds):\n",
        "\n",
        "    print(preds)\n",
        "    # seq of most probable ones in sequence\n",
        "    tags_seq = [np.argmax(p) for p in preds[:len(sentences_seqs[i])]]\n",
        "    words = [sentence_tokenizer.index_word[w] for w in sentences_seqs[i]]\n",
        "    tags = [tag_tokenizer.index_word[t] for t in tags_seq]\n",
        "    sentence_tags.append(list(zip(words, tags)))\n",
        "\n",
        "  return sentence_tags"
      ],
      "metadata": {
        "id": "fjDS3PHZ_DHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_sample_sentences = tag_sentences(samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ot1Wu41vAKZ2",
        "outputId": "766dfe38-e775-420f-c057-e8fa0e7b94a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n",
            "[[3.2334467e-06 9.9331737e-01 2.9946794e-04 ... 3.9344709e-04\n",
            "  1.2747691e-05 2.2187696e-05]\n",
            " [1.2938746e-06 3.1313516e-04 9.9806172e-01 ... 1.4160351e-04\n",
            "  4.5686566e-09 1.3718624e-06]\n",
            " [1.2729881e-06 2.0816846e-05 6.1781978e-04 ... 4.8411652e-01\n",
            "  3.2293276e-05 3.9092065e-06]\n",
            " ...\n",
            " [7.5027689e-02 8.0436386e-02 7.9266421e-02 ... 7.5670168e-02\n",
            "  7.5860150e-02 7.5894080e-02]\n",
            " [7.5027689e-02 8.0436386e-02 7.9266421e-02 ... 7.5670168e-02\n",
            "  7.5860150e-02 7.5894080e-02]\n",
            " [7.5027689e-02 8.0436386e-02 7.9266421e-02 ... 7.5670168e-02\n",
            "  7.5860150e-02 7.5894080e-02]]\n",
            "[[4.2764573e-06 1.5268865e-01 1.3265687e-04 ... 3.5671474e-05\n",
            "  2.9227600e-04 1.2731762e-05]\n",
            " [2.3185294e-08 9.9997950e-01 6.1821049e-07 ... 1.7081586e-06\n",
            "  1.0583433e-06 1.6246985e-06]\n",
            " [4.9634735e-10 3.8132605e-06 9.9999332e-01 ... 1.6310411e-08\n",
            "  2.7530690e-13 1.3395328e-08]\n",
            " ...\n",
            " [7.5027689e-02 8.0436386e-02 7.9266421e-02 ... 7.5670168e-02\n",
            "  7.5860150e-02 7.5894080e-02]\n",
            " [7.5027689e-02 8.0436386e-02 7.9266421e-02 ... 7.5670168e-02\n",
            "  7.5860150e-02 7.5894080e-02]\n",
            " [7.5027689e-02 8.0436386e-02 7.9266421e-02 ... 7.5670168e-02\n",
            "  7.5860150e-02 7.5894080e-02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tagged_sample_sentences[0])\n",
        "print(tagged_sample_sentences[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRumHAfjAOcF",
        "outputId": "b1088276-0b8c-4334-e981-9d76f27ac458"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('brown', 'noun'), ('refused', 'verb'), ('to', 'adp'), ('testify', 'verb')]\n",
            "[('brown', 'adj'), ('sofas', 'noun'), ('are', 'verb'), ('on', 'adp'), ('sale', 'noun')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's just one way of buidling a PoS tagger, these days' PoS tagger is much more sophisticated models in which transfomer is used."
      ],
      "metadata": {
        "id": "sYL-XcXyBwN2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yn1fuCFAB6fo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}